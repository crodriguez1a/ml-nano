{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/carlos/.local/share/virtualenvs/ml-nano-ul5Jz1jF/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 523,545\n",
      "Trainable params: 523,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/carlos/.local/share/virtualenvs/ml-nano-ul5Jz1jF/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 32s 642us/step - loss: -55.7984 - acc: 0.1000 - val_loss: -55.7984 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x111cf50f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "#                                verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=1, batch_size=20, verbose=1) #callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 156us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-55.798349920654296, 0.1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "\n",
    "test_img = x_test[:1]\n",
    "\n",
    "# print(model.layers)\n",
    "\n",
    "# ref: https://towardsdatascience.com/understanding-your-convolution-network-with-visualizations-a4883441533b\n",
    "def visualize_layer(model, test_img, layer_slice:int=2):\n",
    "    layer_outputs = [layer.output for layer in model.layers[:layer_slice]]\n",
    "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "    return activation_model.predict(test_img)\n",
    "\n",
    "activations = visualize_layer(model, test_img)\n",
    "\n",
    "\n",
    "plt.matshow(activations[1][0, :, :, 15], cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
